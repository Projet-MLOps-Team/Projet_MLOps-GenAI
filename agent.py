# agent.py

import os
import json
import requests
from typing import Any, Dict

from dotenv import load_dotenv
load_dotenv()

# ========== CONFIG ==========
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
EMBED_MODEL = os.getenv("EMBED_MODEL", "text-embedding-3-small")
CHROMA_DIR = os.getenv("CHROMA_DIR", "./chroma_store")
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ========== LLM & Embeddings ==========
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.tools import tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langgraph.prebuilt import create_react_agent

# ========== Calculator ==========
import numexpr as ne
from pydantic import BaseModel, Field


class CalcInput(BaseModel):
    expression: str = Field(
        description="Expression math√©matique √† √©valuer, ex: '3*(2+5)**2'"
    )


@tool("calculator", args_schema=CalcInput)
def calculator(expression: str) -> str:
    """Calculette via numexpr pour √©valuer une expression math√©matique."""
    try:
        res = ne.evaluate(expression)
        return str(res.item() if hasattr(res, "item") else res)
    except Exception as e:
        return f"CALC_ERROR: {e}"


# ========== Tavily Search ==========
from langchain_community.tools.tavily_search import TavilySearchResults

web_search_tool = TavilySearchResults(tavily_api_key=TAVILY_API_KEY)

# ========== RAG (Chroma) ==========
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader, PyPDFLoader, CSVLoader

embeddings = OpenAIEmbeddings(model=EMBED_MODEL, api_key=OPENAI_API_KEY)
vectorstore = Chroma(
    collection_name="rag_collection",
    embedding_function=embeddings,
    persist_directory=CHROMA_DIR,
)
retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

RAG_INITIALIZED = False


def download(url: str) -> str:
    """T√©l√©charge un fichier depuis une URL et le stocke dans ./downloaded_docs."""
    os.makedirs("./downloaded_docs", exist_ok=True)
    path = "./downloaded_docs/" + url.split("/")[-1]
    r = requests.get(url)
    r.raise_for_status()
    with open(path, "wb") as f:
        f.write(r.content)
    print("Downloaded", path)
    return path


def ingest_file(path: str) -> int:
    """Ingestion d‚Äôun fichier (PDF/CSV/TXT) dans le vector store Chroma."""
    splitter = RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=120)

    if path.lower().endswith(".pdf"):
        docs = PyPDFLoader(path).load()
    elif path.lower().endswith(".csv"):
        docs = CSVLoader(path).load()
    else:
        docs = TextLoader(path, encoding="utf-8").load()

    chunks = splitter.split_documents(docs)
    vectorstore.add_documents(chunks)
    print(f"Ingested {len(chunks)} chunks from {path}")
    return len(chunks)


def init_rag():
    """Initialise le RAG (t√©l√©charge + ing√®re le PDF) une seule fois."""
    global RAG_INITIALIZED
    if RAG_INITIALIZED:
        return
    url = (
        "https://raw.githubusercontent.com/Projet-MLOps-Team/Projet_MLOps-GenAI/main/conditions-tarifaires-particuliers-2025.pdf"
    )
    path = download(url)
    ingest_file(path)
    RAG_INITIALIZED = True
    print("‚úÖ RAG initialis√© (PDF conditions tarifaires ing√©r√©)")


class RagInput(BaseModel):
    query: str = Field(description="Question en langage naturel.")
    k: int = Field(
        default=5,
        ge=1,
        le=20,
        description="Nombre maximum de passages RAG √† renvoyer.",
    )


@tool("rag_search", args_schema=RagInput)
def rag_search(query: str, k: int = 5) -> str:
    """Recherche des passages pertinents dans le vector store Chroma (RAG)."""
    try:
        docs = retriever.invoke(query)
        if not docs:
            return f"RAG_EMPTY: Aucun document trouv√© pour la requ√™te: {query}"

        docs = docs[:k]
        lines = [f"RAG_HITS: {len(docs)} r√©sultats pour: {query}"]
        for i, d in enumerate(docs, 1):
            meta = d.metadata or {}
            src = meta.get("source") or meta.get("file_path") or "unknown"
            page = meta.get("page", "?")
            txt = d.page_content.replace("\n", " ")
            if len(txt) > 600:
                txt = txt[:600] + "‚Ä¶"
            lines.append(f"[{i}] (page {page}) {src}: {txt}")
        return "\n".join(lines)
    except Exception as e:
        return f"RAG_ERROR: {e}"


# ========== ML Prediction Tool (remote .pkl on S3) ==========
import pandas as pd
import joblib
from io import BytesIO


class MLPredictInput(BaseModel):
    payload: Dict[str, Any] = Field(
        description="Dictionnaire de features pour la pr√©diction ML."
    )


MODEL_URL = "https://mlopsgenaiapp.s3.eu-west-3.amazonaws.com/best_model.pkl"
remote_model = None


def load_remote_model(url: str):
    """T√©l√©charge un mod√®le pickle distant et le charge en m√©moire."""
    print(f"üì° T√©l√©chargement du mod√®le distant : {url}")
    resp = requests.get(url)
    resp.raise_for_status()
    buffer = BytesIO(resp.content)
    model = joblib.load(buffer)
    print("‚úÖ Mod√®le distant charg√© en m√©moire")
    return model


try:
    remote_model = load_remote_model(MODEL_URL)
except Exception as e:
    print(f"‚ùå ERREUR chargement mod√®le distant : {e}")
    remote_model = None


def _align_features(df: pd.DataFrame):
    """Aligne l'ordre et le set de features avec ceux utilis√©s au fit."""
    feature_names = getattr(remote_model, "feature_names_in_", None)
    if feature_names is None:
        return df

    missing = [f for f in feature_names if f not in df.columns]
    if missing:
        raise ValueError(
            f"Features manquantes pour le mod√®le : {missing}. "
            f"Features re√ßues : {list(df.columns)}"
        )

    return df[list(feature_names)]


def _predict_remote(features: Dict[str, Any]) -> Dict[str, Any]:
    """Pr√©diction via mod√®le .pkl charg√© depuis S3, avec sortie enrichie."""
    if remote_model is None:
        raise RuntimeError("Mod√®le distant non charg√©.")

    df = pd.DataFrame([features])
    df = _align_features(df)

    y_pred = remote_model.predict(df)[0]

    proba_default = None
    if hasattr(remote_model, "predict_proba"):
        proba_default = float(remote_model.predict_proba(df)[0, 1])

    if int(y_pred) == 1:
        label_name = "D√©faut probable"
    else:
        label_name = "Client plut√¥t sain"

    risk_level = None
    if proba_default is not None:
        if proba_default < 0.20:
            risk_level = "faible"
        elif proba_default < 0.50:
            risk_level = "mod√©r√©"
        else:
            risk_level = "√©lev√©"

    if proba_default is not None and risk_level is not None:
        explanation = (
            f"Le mod√®le estime une probabilit√© de d√©faut d‚Äôenviron "
            f"{proba_default*100:.1f} %, ce qui correspond √† un risque {risk_level}."
        )
    else:
        explanation = (
            "Le mod√®le ne fournit pas de probabilit√© explicite, seulement une classe pr√©dite."
        )

    return {
        "label": int(y_pred),
        "label_name": label_name,
        "proba_default": proba_default,
        "risk_level": risk_level,
        "explanation": explanation,
        "features_used": list(df.columns),
    }


def _jsonable(x: Any) -> Any:
    """Conversion best-effort en objet JSON-serialisable."""
    try:
        json.dumps(x)
        return x
    except TypeError:
        if hasattr(x, "tolist"):
            return x.tolist()
        return str(x)


@tool("ml_predict", args_schema=MLPredictInput)
def ml_predict(payload: Dict[str, Any]) -> str:
    """Effectue une pr√©diction via un mod√®le .pkl h√©berg√© sur S3, avec sortie enrichie."""
    try:
        result = _predict_remote(payload)
        pretty = {
            "kind": "remote_pickle",
            "prediction": _jsonable(result),
        }
        return json.dumps(pretty, ensure_ascii=False, indent=2)
    except Exception as e:
        return f"ML_ERROR: {e}"


# ========== SYSTEM PROMPT (texte) ==========
SYSTEM_PROMPT_TEXT = """
Tu es un assistant bancaire expert en d√©faut de cr√©dit et conditions tarifaires 2025, dot√© d‚Äôune m√©moire contextuelle
et de plusieurs outils sp√©cialis√©s. Ton r√¥le est de s√©lectionner automatiquement l‚Äôoutil pertinent,
d'utiliser intelligemment la m√©moire issue du RAG, et de produire une r√©ponse synth√©tique, fiable et syst√©matique.

[ M√âMOIRE ]
- Consid√®re le contenu index√© dans le RAG comme ta m√©moire fiable pour les tarifs bancaires.
- Consulte syst√©matiquement `rag_search` pour toute requ√™te li√©e √† : tarifs, frais, commissions, comptes, cartes,
  packages, virements, incidents, client√®le (r√©sident / non r√©sident, jeune, premium, etc.).
- Ne JAMAIS inventer de montant : si les documents ne contiennent pas l‚Äôinformation, dis-le explicitement.

[ CHOIX DES OUTILS ]
1) RAG (`rag_search`) ‚Äì PRIORITAIRE :
   - Utilise-le quand la question concerne des tarifs, frais, conditions, offres, segments de client√®le.
   - Formule une requ√™te courte, pr√©cise, en fran√ßais (ex: ‚Äútenue de compte actif non r√©sident‚Äù).

2) Web Search (`web_search_tool`) :
   - Utilise-le pour les actualit√©s, contexte macro, informations externes non pr√©sentes dans les documents.
   - Ne pas l‚Äôutiliser pour confirmer un chiffre qui devrait venir du PDF.

3) ML Prediction (`ml_predict`) :
   - Utilise-le si l‚Äôutilisateur demande une estimation de risque cr√©dit ou une pr√©diction √† partir de features.
   - Transmets fid√®lement les features fournies et explique le r√©sultat (classe, probabilit√©, niveau de risque).

4) Calculator (`calculator`) :
   - Utilise-le pour les calculs math√©matiques explicites (montants, pourcentages, ratios).

[ COMPORTEMENT ]
- Si la question peut utiliser plusieurs outils, privil√©gie d‚Äôabord `rag_search`.
- Si `rag_search` renvoie RAG_EMPTY ou RAG_ERROR, explique que l‚Äôinfo n‚Äôest pas dans les documents et n‚Äôinvente rien.
- Si aucun outil n‚Äôest pertinent, demande une clarification courte ou r√©ponds avec ce que tu peux d√©duire sans halluciner.

[ STYLE ]
- Toujours en fran√ßais.
- R√©ponses claires, concises, structur√©es.
- Pour les tarifs, privil√©gie un tableau (type de compte | client | montant | p√©riodicit√©) + une courte synth√®se.
""".strip()


# ========== Agent factory ==========
def build_agent():
    """Construit l‚Äôagent ReAct avec les tools calcul, RAG, web et ML."""
    init_rag()

    llm = ChatOpenAI(
        model=OPENAI_MODEL,
        api_key=OPENAI_API_KEY,
        temperature=0,
    )
    tools = [calculator, rag_search, web_search_tool]
    if remote_model is not None:
        tools.append(ml_predict)

    # Prompt compatible avec create_react_agent (version r√©cente) :
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", SYSTEM_PROMPT_TEXT),
            MessagesPlaceholder("messages"),
        ]
    )

    return create_react_agent(
        llm,
        tools,
        prompt=prompt,
    )


def chat(agent, messages: list, recursion_limit: int = 40) -> str:
    """
    messages = liste de dicts {"role": "user"/"assistant", "content": "..."}
    On convertit au format attendu par LangGraph: [("user", "..."), ("assistant", "..."), ...]
    """
    try:
        lc_messages = [(m["role"], m["content"]) for m in messages]
        out = agent.invoke(
            {"messages": lc_messages},
            config={"recursion_limit": recursion_limit},
        )
        return out["messages"][-1].content
    except Exception as e:
        return f"AGENT_ERROR: {e}"



# ========== MAIN ==========
if __name__ == "__main__":
    print("Bootstrapping agent...")

    agent = build_agent()

    print("\n[Calc]")
    print(chat(agent, "Calcule 3*(2+5)**2 et explique en une ligne."))

    print("\n[RAG]")
    print(
        chat(
            agent,
            "R√©sume-moi les frais de tenue de compte pour un non r√©sident en utilisant ton outil rag_search.",
        )
    )

    print("\n[ML]")
    print(
        chat(
            agent,
            "Appelle ml_predict avec "
            "{'credit_lines_outstanding': 5, 'loan_amt_outstanding': 15000, "
            "'total_debt_outstanding': 25000, 'income': 60000, 'years_employed': 10, "
            "'fico_score': 720, 'debt_ratio': 0.3} et explique le r√©sultat.",
        )
    )
