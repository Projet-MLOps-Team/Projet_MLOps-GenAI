# ğŸ§  MLOps Ã— GenAI â€” Loan Default Assistant

## ğŸ” Introduction

Ce projet end-to-end combine **Machine Learning** et **GÃ©nÃ©ration augmentÃ©e par la recherche (RAG)** pour aider une banque de dÃ©tail Ã  prÃ©dire le risque de dÃ©faut sur des prÃªts et interroger un assistant intelligent capable de :

- ğŸ“„ **RÃ©pondre via RAG** Ã  partir d'un document interne (`ragdoc.pdf`)
- ğŸ¤– **Faire des prÃ©dictions ML** sur le risque de dÃ©faut
- ğŸ§® **RÃ©aliser des calculs** arithmÃ©tiques simples
- ğŸŒ **Lancer des recherches web** 

## ğŸ¯ Objectifs du Projet

1. Construire un **modÃ¨le supervisÃ© de classification** qui estime la probabilitÃ© de dÃ©faut
2. Exposer un **agent LangChain multi-outils** dans une application Streamlit
3. **Dockeriser** l'application pour un dÃ©ploiement reproductible
4. Automatiser le **dÃ©ploiement via CI/CD** (GitHub Actions â†’ Hugging Face Spaces)

## ğŸ“Š Jeu de DonnÃ©es

Le fichier `data.csv` contient des informations de demandeurs de prÃªts et leur statut de dÃ©faut.

### Variables

- **Features**: `credit_lines_outstanding`, `loan_amt_outstanding`, `total_debt_outstanding`, `income`, `years_employed`, `fico_score`
- **Target**: `default` âˆˆ {0, 1}
- **Feature Engineering**: `debt_ratio = total_debt_outstanding / income` (crÃ©Ã©e par `eda.py`)

âš ï¸ **Note**: Le dataset peut Ãªtre dÃ©sÃ©quilibrÃ©. Le modÃ¨le gÃ¨re cela via `class_weight='balanced'` et un seuil ajustable.

## ğŸ—‚ï¸ Structure du Projet
```
loan-default-assistant/
â”‚
â”œâ”€â”€ data.csv                    # DonnÃ©es brutes
â”œâ”€â”€ eda.py                      # EDA + nettoyage â†’ datafinal.csv
â”œâ”€â”€ datafinal.csv               # DonnÃ©es prÃ©parÃ©es
â”‚
â”œâ”€â”€ train.py                    # EntraÃ®nement + export best_model.joblib
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_model.joblib       # ModÃ¨le sÃ©lectionnÃ©
â”‚   â””â”€â”€ meta.json               # MÃ©tadonnÃ©es
â”‚
â”œâ”€â”€ langchainagent.py           # Agent LangChain (4 outils)
â”œâ”€â”€ app.py                      # Interface Streamlit
â”œâ”€â”€ ragdoc.pdf                  # Document interne pour RAG
â”‚
â”œâ”€â”€ requirements.txt            # DÃ©pendances Python
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy-huggingface.yml  # Pipeline CI/CD
â”‚
â””â”€â”€ README.md                   # Cette documentation
```

## ğŸš€ Installation et Utilisation

### PrÃ©requis
```bash
Python 3.9+
OpenAI API Key ou autre LLM compatible
```

### Installation Locale
```bash
# 1. Cloner le repository
git clone https://github.com/Projet-MLOps-Team/Projet_MLOps-GenAI.git
cd Projet_MLOps-GenAI

# 2. CrÃ©er un environnement virtuel
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# 3. Installer les dÃ©pendances
pip install --upgrade pip
pip install -r requirements.txt

# 4. Configurer les clÃ©s API
export OPENAI_API_KEY="sk-..."
```

### Pipeline Complet

#### 1ï¸âƒ£ PrÃ©paration des DonnÃ©es
```bash
python eda.py
# â†’ GÃ©nÃ¨re datafinal.csv
```

**OpÃ©rations effectuÃ©es:**
- Nettoyage des valeurs manquantes
- DÃ©tection et traitement des outliers
- Feature engineering (`debt_ratio`)
- Normalisation des variables

#### 2ï¸âƒ£ EntraÃ®nement du ModÃ¨le
```bash
python train.py
# â†’ models/best_model.joblib + models/meta.json
```

**ModÃ¨les testÃ©s:**
- Logistic Regression
- Decision Tree
- Random Forest â­

**SÃ©lection:** BasÃ©e sur **PR AUC** (Precision-Recall Area Under Curve)

#### 3ï¸âƒ£ Lancer l'Application
```bash
streamlit run app.py
# â†’ http://localhost:8501
```

## ğŸ§© Agent LangChain - 4 Outils

### 1. ğŸ“„ RAG Tool
Interroge le document `ragdoc.pdf` pour rÃ©pondre aux questions internes.

### 2. ğŸ¤– ML Predict Tool
PrÃ©diction de dÃ©faut basÃ©e sur `best_model.joblib`.

### 3. ğŸ§® Calculator Tool
Calculs arithmÃ©tiques sÃ©curisÃ©s.

### 4. ğŸŒ Web Search Tool
Recherche DuckDuckGo pour informations externes.

## ğŸ’¬ Interface Streamlit

### FonctionnalitÃ©s

- **Chat unifiÃ©** : Questions RAG, ML, calculs, recherche web
- **PrÃ©dictions ML** : Ã‰valuation du risque de dÃ©faut
- **Ingestion RAG** : RÃ©ponses depuis documents internes
- **Interface intuitive** : Conversation naturelle

# Classification supervisÃ©e avec suivi MLflow

## 1. PrÃ©sentation du projet

Ce projet implÃ©mente une comparaison de modÃ¨les de classification supervisÃ©e Ã  lâ€™aide de **trois algorithmes** :

* RÃ©gression Logistique
* Arbre de DÃ©cision
* Random Forest

Lâ€™objectif est de proposer une approche complÃ¨te intÃ©grant la **gestion du dÃ©sÃ©quilibre des classes**, la **recherche dâ€™hyperparamÃ¨tres**, lâ€™**optimisation du seuil de dÃ©cision** et le **suivi expÃ©rimental avec MLflow**.

---

## 2. Objectifs principaux

* EntraÃ®ner **trois modÃ¨les** sur un jeu de donnÃ©es CSV (features + colonne cible).
* GÃ©rer le **dÃ©sÃ©quilibre de classes** via `class_weight` et/ou `sample_weight`.
* (Optionnel) Effectuer une **recherche dâ€™hyperparamÃ¨tres** avec `RandomizedSearchCV`.
* Comparer les performances Ã  lâ€™aide des mÃ©triques suivantes :

  * AUC (ROC)
  * AUPRC (PR-AUC)
  * Accuracy
  * F1-score
  * Precision
  * Recall
  * Log Score

* Trouver le **seuil de dÃ©cision optimal** maximisant le F1-score de la **classe minoritaire**.
* Sauvegarder le **meilleur pipeline** dans le rÃ©pertoire :

  ```
  mlflow_artifacts/nom_modele
  best_model_local.pkl

  ```
* Enregistrer lâ€™ensemble des **mÃ©triques, figures et rÃ©sultats** dans **MLflow**, incluant :

  * Matrice de confusion
  * Courbes ROC et Precision-Recall

---

## 3. FonctionnalitÃ©s principales

| FonctionnalitÃ©           | Description                                             |
| ------------------------ | ------------------------------------------------------- |
| ModÃ¨les Ã©valuÃ©s          | RÃ©gression Logistique, Arbre de DÃ©cision, Random Forest |
| Gestion du dÃ©sÃ©quilibre  | `class_weight` et/ou `sample_weight`                    |
| Tuning dâ€™hyperparamÃ¨tres | `RandomizedSearchCV` (optionnel)                        |
| Optimisation du seuil    | Recherche du seuil maximisant le F1-score minoritaire   |
| Suivi expÃ©rimental       | Logging complet avec MLflow                             |
| Export final             | `artifacts/best_model.joblib`                           |

---

## 4. MÃ©triques et visualisations

Les performances sont Ã©valuÃ©es selon plusieurs indicateurs :

* AUC (ROC)
* AUPRC (PR-AUC)
* Accuracy
* F1-score (global et minoritaire)
* Log loss

Les visualisations enregistrÃ©es dans MLflow comprennent :

* Matrice de confusion
* Courbe ROC
* Courbe Precision-Recall
* Comparatif global des modÃ¨les

---

## 5. Structure du projet (exemple)

```
.
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dataset.csv
â”œâ”€â”€ mlflow_artifacts/
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â””â”€â”€ roc_curve.png
â”œâ”€â”€ mlruns/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_artefacts.py
â”‚   â”œâ”€â”€ data_processing.py
â”‚   â”œâ”€â”€ metrics.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ save_best_model.py
â”‚   â”œâ”€â”€ train_experiment.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ best_model_local.pkl
|
â”œâ”€â”€ main.py
â”‚   
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## 6. Lancement rapide

### Installation des dÃ©pendances

```bash
pip install -r requirements.txt
```

### Lancement de lâ€™interface MLflow

```bash
mlflow ui --backend-store-uri mlruns --default-artifact-root mlruns --host 127.0.0.1 --port 5000 
```

### EntraÃ®nement des modÃ¨les

```bash
python src/train.py --data data/dataset.csv
```

### Consultation des rÃ©sultats

* Interface MLflow : [http://localhost:5000](http://localhost:5000)
* ModÃ¨le final enregistrÃ© : `artifacts/best_model.joblib`

---

## 7. Environnement et dÃ©pendances

* Python 3.x
* scikit-learn
* MLflow
* pandas
* numpy
* matplotlib
* seaborn
* joblib
---
title: Loan Default Prediction
emoji: ğŸ¦
sdk: streamlit
sdk_version: "1.32.0"
app_file: app.py
---
